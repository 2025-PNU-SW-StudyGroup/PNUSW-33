{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67dec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'21038': 0, '21116': 1, '21211': 2, '22333': 3, '22973': 4, '22976': 5, '24272': 6, '24292': 7, '24322': 8, '41663': 9, '41778': 10, '41970': 11, '42007': 12, '42087': 13, '42113': 14, '46010': 15, '47067': 16, '48124': 17, '50186': 18, '52884': 19, '64862': 20, '65336': 21, '65344': 22, '65349': 23, '65373': 24, '65419': 25, '65448': 26, '65547': 27, '65962': 28, '66016': 29, '66531': 30, '66578': 31, '66893': 32, '67082': 33, '67252': 34, '81930': 35, '126247': 36, '134933': 37, '135045': 38, '476537': 39, '476538': 40, '517119': 41, '523060': 42, '528041': 43, '548639': 44, '555086': 45, '555142': 46, '566513': 47, '714022': 48, '715170': 49, '787625': 50, '868458': 51, '963335': 52, '1139490': 53, '1192948': 54, '1194042': 55, '1346504': 56, '1462711': 57, '1462737': 58, '1564122': 59, 'amakin1': 60, 'amekes': 61, 'ampkin1': 62, 'anhing': 63, 'babwar': 64, 'bafibi1': 65, 'banana': 66, 'baymac': 67, 'bbwduc': 68, 'bicwre1': 69, 'bkcdon': 70, 'bkmtou1': 71, 'blbgra1': 72, 'blbwre1': 73, 'blcant4': 74, 'blchaw1': 75, 'blcjay1': 76, 'blctit1': 77, 'blhpar1': 78, 'blkvul': 79, 'bobfly1': 80, 'bobher1': 81, 'brtpar1': 82, 'bubcur1': 83, 'bubwre1': 84, 'bucmot3': 85, 'bugtan': 86, 'butsal1': 87, 'cargra1': 88, 'cattyr': 89, 'chbant1': 90, 'chfmac1': 91, 'cinbec1': 92, 'cocher1': 93, 'cocwoo1': 94, 'colara1': 95, 'colcha1': 96, 'compau': 97, 'compot1': 98, 'cotfly1': 99, 'crbtan1': 100, 'crcwoo1': 101, 'crebob1': 102, 'cregua1': 103, 'creoro1': 104, 'eardov1': 105, 'fotfly': 106, 'gohman1': 107, 'grasal4': 108, 'grbhaw1': 109, 'greani1': 110, 'greegr': 111, 'greibi1': 112, 'grekis': 113, 'grepot1': 114, 'gretin1': 115, 'grnkin': 116, 'grysee1': 117, 'gybmar': 118, 'gycwor1': 119, 'labter1': 120, 'laufal1': 121, 'leagre': 122, 'linwoo1': 123, 'littin1': 124, 'mastit1': 125, 'neocor': 126, 'norscr1': 127, 'olipic1': 128, 'orcpar': 129, 'palhor2': 130, 'paltan1': 131, 'pavpig2': 132, 'piepuf1': 133, 'pirfly1': 134, 'piwtyr1': 135, 'plbwoo1': 136, 'plctan1': 137, 'plukit1': 138, 'purgal2': 139, 'ragmac1': 140, 'rebbla1': 141, 'recwoo1': 142, 'rinkin1': 143, 'roahaw': 144, 'rosspo1': 145, 'royfly1': 146, 'rtlhum': 147, 'rubsee1': 148, 'rufmot1': 149, 'rugdov': 150, 'rumfly1': 151, 'ruther1': 152, 'rutjac1': 153, 'rutpuf1': 154, 'saffin': 155, 'sahpar1': 156, 'savhaw1': 157, 'secfly1': 158, 'shghum1': 159, 'shtfly1': 160, 'smbani': 161, 'snoegr': 162, 'sobtyr1': 163, 'socfly1': 164, 'solsan': 165, 'soulap1': 166, 'spbwoo1': 167, 'speowl1': 168, 'spepar1': 169, 'srwswa1': 170, 'stbwoo2': 171, 'strcuc1': 172, 'strfly1': 173, 'strher': 174, 'strowl1': 175, 'tbsfin1': 176, 'thbeup1': 177, 'thlsch3': 178, 'trokin': 179, 'tropar': 180, 'trsowl': 181, 'turvul': 182, 'verfly': 183, 'watjac1': 184, 'wbwwre1': 185, 'whbant1': 186, 'whbman1': 187, 'whfant1': 188, 'whmtyr1': 189, 'whtdov': 190, 'whttro1': 191, 'whwswa1': 192, 'woosto': 193, 'y00678': 194, 'yebela1': 195, 'yebfly1': 196, 'yebsee1': 197, 'yecspi2': 198, 'yectyr1': 199, 'yehbla2': 200, 'yehcar1': 201, 'yelori1': 202, 'yeofly1': 203, 'yercac1': 204, 'ywcpar': 205}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "AUDIO_ROOT = 'C:/Users/tkddn/code/kaggle/train_audio'\n",
    "\n",
    "def natural_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "\n",
    "species_list = sorted(\n",
    "    [d for d in os.listdir(AUDIO_ROOT) if os.path.isdir(os.path.join(AUDIO_ROOT, d))],\n",
    "    key=natural_key\n",
    ")\n",
    "\n",
    "# 라벨 딕셔너리\n",
    "label_dict = {species: idx for idx, species in enumerate(species_list)}\n",
    "\n",
    "# 저장\n",
    "with open('class_to_label.pkl', 'wb') as f:\n",
    "    pickle.dump(label_dict, f)\n",
    "\n",
    "with open('class_to_label.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['species', 'label'])\n",
    "    for species, label in label_dict.items():\n",
    "        writer.writerow([species, label])\n",
    "\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686ef3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from efficientnet_pytorch) (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch->efficientnet_pytorch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tkddn\\anaconda3\\lib\\site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.1/6.2 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 11.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: efficientnet_pytorch\n",
      "  Building wheel for efficientnet_pytorch (setup.py): started\n",
      "  Building wheel for efficientnet_pytorch (setup.py): finished with status 'done'\n",
      "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16458 sha256=a2ed77315e4bf14b02cf7de7dbd77ded30c6592b46680587cdb39d8f810ee776\n",
      "  Stored in directory: c:\\users\\tkddn\\appdata\\local\\pip\\cache\\wheels\\9c\\3f\\43\\e6271c7026fe08c185da2be23c98c8e87477d3db63f41f32ad\n",
      "Successfully built efficientnet_pytorch\n",
      "Installing collected packages: sympy, efficientnet_pytorch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed efficientnet_pytorch-0.7.1 sympy-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356a611",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes 1139490, 1192948, 1194042, 126247, 1346504, 134933, 135045, 1462711, 1462737, 1564122, 21038, 21116, 21211, 22333, 22973, 22976, 24272, 24292, 24322, 41663, 41778, 41970, 42007, 42087, 42113, 46010, 47067, 476537, 476538, 48124, 50186, 517119, 523060, 528041, 52884, 548639, 555086, 555142, 566513, 64862, 65336, 65344, 65349, 65373, 65419, 65448, 65547, 65962, 66016, 66531, 66578, 66893, 67082, 67252, 714022, 715170, 787625, 81930, 868458, 963335, amakin1, amekes, ampkin1, anhing, babwar, bafibi1, banana, baymac, bbwduc, bicwre1, bkcdon, bkmtou1, blbgra1, blbwre1, blcant4, blchaw1, blcjay1, blctit1, blhpar1, blkvul, bobfly1, bobher1, brtpar1, bubcur1, bubwre1, bucmot3, bugtan, butsal1, cargra1, cattyr, chbant1, chfmac1, cinbec1, cocher1, cocwoo1, colara1, colcha1, compau, compot1, cotfly1, crbtan1, crcwoo1, crebob1, cregua1, creoro1, eardov1, fotfly, gohman1, grasal4, grbhaw1, greani1, greegr, greibi1, grekis, grepot1, gretin1, grnkin, grysee1, gybmar, gycwor1, labter1, laufal1, leagre, linwoo1, littin1, mastit1, neocor, norscr1, olipic1, orcpar, palhor2, paltan1, pavpig2, piepuf1, pirfly1, piwtyr1, plbwoo1, plctan1, plukit1, purgal2, ragmac1, rebbla1, recwoo1, rinkin1, roahaw, rosspo1, royfly1, rtlhum, rubsee1, rufmot1, rugdov, rumfly1, ruther1, rutjac1, rutpuf1, saffin, sahpar1, savhaw1, secfly1, shghum1, shtfly1, smbani, snoegr, sobtyr1, socfly1, solsan, soulap1, spbwoo1, speowl1, spepar1, srwswa1, stbwoo2, strcuc1, strfly1, strher, strowl1, tbsfin1, thbeup1, thlsch3, trokin, tropar, trsowl, turvul, verfly, watjac1, wbwwre1, whbant1, whbman1, whfant1, whmtyr1, whtdov, whttro1, whwswa1, woosto, y00678, yebela1, yebfly1, yebsee1, yecspi2, yectyr1, yehbla2, yehcar1, yelori1, yeofly1, yercac1, ywcpar. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 2️⃣ 데이터 전처리 및 데이터셋 준비\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[0;32m     22\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     23\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m224\u001b[39m),              \u001b[38;5;66;03m# EfficientNet 기본 입력 크기\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     25\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize([\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m],  \u001b[38;5;66;03m# ImageNet 평균\u001b[39;00m\n\u001b[0;32m     26\u001b[0m                          [\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])  \u001b[38;5;66;03m# ImageNet 표준편차\u001b[39;00m\n\u001b[0;32m     27\u001b[0m ])\n\u001b[1;32m---> 29\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[0;32m     32\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m-\u001b[39m train_size\n",
      "File \u001b[1;32mc:\\Users\\tkddn\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\tkddn\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:150\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m    149\u001b[0m classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_classes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[1;32m--> 150\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions \u001b[38;5;241m=\u001b[39m extensions\n",
      "File \u001b[1;32mc:\\Users\\tkddn\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:203\u001b[0m, in \u001b[0;36mDatasetFolder.make_dataset\u001b[1;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tkddn\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:104\u001b[0m, in \u001b[0;36mmake_dataset\u001b[1;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextensions\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(extensions,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m instances\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Found no valid file for the classes 1139490, 1192948, 1194042, 126247, 1346504, 134933, 135045, 1462711, 1462737, 1564122, 21038, 21116, 21211, 22333, 22973, 22976, 24272, 24292, 24322, 41663, 41778, 41970, 42007, 42087, 42113, 46010, 47067, 476537, 476538, 48124, 50186, 517119, 523060, 528041, 52884, 548639, 555086, 555142, 566513, 64862, 65336, 65344, 65349, 65373, 65419, 65448, 65547, 65962, 66016, 66531, 66578, 66893, 67082, 67252, 714022, 715170, 787625, 81930, 868458, 963335, amakin1, amekes, ampkin1, anhing, babwar, bafibi1, banana, baymac, bbwduc, bicwre1, bkcdon, bkmtou1, blbgra1, blbwre1, blcant4, blchaw1, blcjay1, blctit1, blhpar1, blkvul, bobfly1, bobher1, brtpar1, bubcur1, bubwre1, bucmot3, bugtan, butsal1, cargra1, cattyr, chbant1, chfmac1, cinbec1, cocher1, cocwoo1, colara1, colcha1, compau, compot1, cotfly1, crbtan1, crcwoo1, crebob1, cregua1, creoro1, eardov1, fotfly, gohman1, grasal4, grbhaw1, greani1, greegr, greibi1, grekis, grepot1, gretin1, grnkin, grysee1, gybmar, gycwor1, labter1, laufal1, leagre, linwoo1, littin1, mastit1, neocor, norscr1, olipic1, orcpar, palhor2, paltan1, pavpig2, piepuf1, pirfly1, piwtyr1, plbwoo1, plctan1, plukit1, purgal2, ragmac1, rebbla1, recwoo1, rinkin1, roahaw, rosspo1, royfly1, rtlhum, rubsee1, rufmot1, rugdov, rumfly1, ruther1, rutjac1, rutpuf1, saffin, sahpar1, savhaw1, secfly1, shghum1, shtfly1, smbani, snoegr, sobtyr1, socfly1, solsan, soulap1, spbwoo1, speowl1, spepar1, srwswa1, stbwoo2, strcuc1, strfly1, strher, strowl1, tbsfin1, thbeup1, thlsch3, trokin, tropar, trsowl, turvul, verfly, watjac1, wbwwre1, whbant1, whbman1, whfant1, whmtyr1, whtdov, whttro1, whwswa1, woosto, y00678, yebela1, yebfly1, yebsee1, yecspi2, yectyr1, yehbla2, yehcar1, yelori1, yeofly1, yercac1, ywcpar. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# ============================\n",
    "# 1️⃣ 데이터 경로 및 설정\n",
    "# ============================\n",
    "DATA_DIR = 'C:/Users/tkddn/code/kaggle/train_audio_mel'  # 멜 스펙 저장된 폴더\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# ============================\n",
    "# 2️⃣ 데이터 전처리 및 데이터셋 준비\n",
    "# ============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),              # EfficientNet 기본 입력 크기\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet 평균\n",
    "                         [0.229, 0.224, 0.225])  # ImageNet 표준편차\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# ============================\n",
    "# 3️⃣ EfficientNet 모델 생성 및 수정\n",
    "# ============================\n",
    "num_classes = len(dataset.classes)\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "in_features = model._fc.in_features\n",
    "model._fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# ============================\n",
    "# 4️⃣ 손실함수, 옵티마이저, 스케줄러 정의\n",
    "# ============================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# ============================\n",
    "# 5️⃣ 학습 및 검증 함수 정의\n",
    "# ============================\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def eval_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ============================\n",
    "# 6️⃣ 메인 학습 루프 실행\n",
    "# ============================\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = eval_epoch(model, val_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# 7️⃣ 학습된 모델 저장\n",
    "# ============================\n",
    "torch.save(model.state_dict(), 'efficientnet_birdclef.pth')\n",
    "print(\"✅ 모델 저장 완료! 경로: efficientnet_birdclef.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dbe99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
