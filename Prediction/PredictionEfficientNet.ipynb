{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1554c49-dbd0-4758-8db7-c3407d2043d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "IMG_DIR = './soundscape_melspec_images'\n",
    "MODEL_PATH = 'efficientnet_birdclef.pth'\n",
    "LABEL_PATH = 'class_to_label.pkl'\n",
    "OUTPUT_CSV = 'soundscape_predictions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64010b-8c92-4f67-9d59-b8d73746dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABEL_PATH, 'rb') as f:\n",
    "    label_dict = pickle.load(f)\n",
    "idx_to_class = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471db9ba-c5cd-4fb2-9846-058147390c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EfficientNet.from_name('efficientnet-b0')\n",
    "in_features = model._fc.in_features\n",
    "model._fc = torch.nn.Linear(in_features, len(label_dict))\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f40129-8603-4db5-b4fb-8a14c2b4b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b816a-b8de-43bf-a2ba-7e17404c5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_CSV, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['filename'] + [idx_to_class[i] for i in range(len(label_dict))])\n",
    "    \n",
    "    for fname in sorted(os.listdir(IMG_DIR)):\n",
    "        if not fname.endswith('.png'):\n",
    "            continue\n",
    "        try:\n",
    "            path = os.path.join(IMG_DIR, fname)\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(tensor)\n",
    "                probs = F.softmax(output, dim=1).cpu().numpy().flatten()\n",
    "\n",
    "            # 소수점 17자리로 포맷팅\n",
    "            probs_formatted = [f\"{p:.17f}\" for p in probs]\n",
    "            writer.writerow([fname[:-4]] + probs_formatted)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {fname} error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642da71-ecae-42fe-9a2a-6138d88d5a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.1.0",
   "language": "python",
   "name": "torch21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
